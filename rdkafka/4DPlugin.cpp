/* --------------------------------------------------------------------------------
 #
 #	4DPlugin.cpp
 #	source generated by 4D Plugin Wizard
 #	Project : RDKAFKA
 #	author : miyako
 #	2017/11/20
 #
 # --------------------------------------------------------------------------------*/


#include "4DPluginAPI.h"
#include "4DPlugin.h"

#pragma mark -

rd_kafka_resp_err_t rd_metadata(rd_kafka_t *rk,
																rd_kafka_topic_t *rkt,
																const struct rd_kafka_metadata **metadata,
																C_LONGINT& returnValue)
{
	int timeout_ms = 5000;
	rd_kafka_resp_err_t err = rd_kafka_metadata(rk, rkt ? 0 : 1, rkt, metadata, timeout_ms);
	returnValue.setIntValue(err);
	
	return err;
}

rd_kafka_t *rd_new(rd_kafka_type_t type, rd_kafka_conf_t *conf)
{
	char errstr[512];
	rd_kafka_t *rk = rd_kafka_new(type, conf, errstr, sizeof(errstr));
	
	if(!rk)
	{
		rd_kafka_conf_destroy(conf);
	}else
	{
		/* rd_kafka_new() owns conf */
	}
	conf = 0;
	
	return rk;
}

rd_kafka_topic_t *rd_topic_new(rd_kafka_t *rk,
															 const char *topic,
															 rd_kafka_topic_conf_t *topic_conf,
															 C_LONGINT& returnValue)
{
	
	rd_kafka_topic_t *rkt = rd_kafka_topic_new(rk, topic, topic_conf);
	
	if(!rkt)
	{
		rd_kafka_topic_conf_destroy(topic_conf);
		returnValue.setIntValue(rd_kafka_last_error());
	}else
	{
		/* rd_kafka_topic_new() owns topic_conf */
	}
	topic_conf = 0;
	
	return rkt;
}

int rd_consume_start(rd_kafka_topic_t *rkt,
										 int32_t partition,
										 int64_t offset,
										 C_LONGINT& returnValue)
{
	int ret = rd_kafka_consume_start(rkt, partition, offset);
	if(ret == -1)
	{
		returnValue.setIntValue(rd_kafka_last_error());
	}
	
	return ret;
}

int rd_kafka_set_rk_brokers(ARRAY_TEXT& param_brokers,
														rd_kafka_t *rk,
														C_LONGINT& returnValue)
{
	CUTF8String brokers;
	for(int i = 1; i < param_brokers.getSize();++i)
	{
		if(i != 1)
		{
			brokers += (const uint8_t *)",";
		}
		CUTF8String _brokers;
		param_brokers.copyUTF8StringAtIndex(&_brokers, i);
		brokers += _brokers;
	}
	int added = rd_kafka_brokers_add(rk, (const char *)brokers.c_str());
	
	if(!added)
	{
		returnValue.setIntValue(rd_kafka_last_error());
	}

	return added;
}

rd_kafka_conf_res_t rd_kafka_set_conf_broker(rd_kafka_topic_conf_t *topic_conf,
																						 C_LONGINT& returnValue)
{
	char errstr[512];
	rd_kafka_conf_res_t res = rd_kafka_topic_conf_set(topic_conf,
																										"offset.store.method",
																										"broker",
																										errstr, sizeof(errstr));
	if(res != RD_KAFKA_CONF_OK)
	{
		returnValue.setIntValue(rd_kafka_last_error());
	}
	return res;
}

rd_kafka_conf_res_t rd_kafka_set_conf_group(rd_kafka_conf_t *conf,
																						const char *group,
																						C_LONGINT& returnValue)
{
	char errstr[512];
	rd_kafka_conf_res_t res = rd_kafka_conf_set(conf,
																							"group.id",
																							group,
																							errstr, sizeof(errstr));
	if(res != RD_KAFKA_CONF_OK)
	{
		returnValue.setIntValue(rd_kafka_last_error());
	}
	return res;
}

rd_kafka_conf_res_t rd_kafka_set_conf_brokers(ARRAY_TEXT& param_brokers,
																							rd_kafka_conf_t *conf,
																							C_LONGINT& returnValue)
{
	CUTF8String brokers;
	for(int i = 1; i < param_brokers.getSize();++i)
	{
		if(i != 1)
		{
			brokers += (const uint8_t *)",";
		}
		CUTF8String _brokers;
		param_brokers.copyUTF8StringAtIndex(&_brokers, i);
		brokers += _brokers;
	}
	char errstr[512];
	rd_kafka_conf_res_t res = rd_kafka_conf_set(conf,
																							"bootstrap.servers",
																							(const char *)brokers.c_str(),
																							errstr, sizeof(errstr));
	if(res != RD_KAFKA_CONF_OK)
	{
		returnValue.setIntValue(rd_kafka_last_error());
	}
	return res;
}

#pragma mark -

bool IsProcessOnExit()
{
	C_TEXT name;
	PA_long32 state, time;
	PA_GetProcessInfo(PA_GetCurrentProcessNumber(), name, &state, &time);
	CUTF16String procName(name.getUTF16StringPtr());
	CUTF16String exitProcName((PA_Unichar *)"$\0x\0x\0\0\0");
	return (!procName.compare(exitProcName));
}

void OnStartup()
{
	
}

void OnCloseProcess()
{
	if(IsProcessOnExit())
	{
		/* Let background threads clean up and terminate cleanly. */
		int run = 5;
		while (run-- > 0 && rd_kafka_wait_destroyed(1000) == RD_KAFKA_RESP_ERR_UNKNOWN)
		{
			PA_YieldAbsolute();
		}
	}
}

#pragma mark -

void json_stringify(JSONNODE *json, C_TEXT& param, BOOL pretty)
{
#if VERSIONMAC
	json_char *json_string = pretty ? json_write_formatted(json) : json_write(json);
	std::wstring wstr = std::wstring(json_string);
	uint32_t dataSize = (uint32_t)((wstr.length() * sizeof(wchar_t))+ sizeof(PA_Unichar));
	std::vector<char> buf(dataSize);
	//returns byte size in toString (in this case, need to /2 to get characters)
	uint32_t len = PA_ConvertCharsetToCharset((char *)wstr.c_str(),
																						(PA_long32)(wstr.length() * sizeof(wchar_t)),
																						eVTC_UTF_32,
																						(char *)&buf[0],
																						dataSize,
																						eVTC_UTF_16);
	param.setUTF16String((const PA_Unichar *)&buf[0], len/sizeof(PA_Unichar));
	json_free(json_string);
#else
	json_char *json_string = pretty ? json_write_formatted(json) : json_write(json);
	std::wstring wstr = std::wstring(json_string);
	param.setUTF16String((const PA_Unichar *)wstr.c_str(), wstr.length());
	json_free(json_string);
#endif
}

void json_wconv(const char *value, std::wstring &u32)
{
	if((value) && strlen(value))
	{
		C_TEXT t;
		CUTF8String u8 = CUTF8String((const uint8_t *)value);
		
		t.setUTF8String(&u8);
		
		uint32_t dataSize = (t.getUTF16Length() * sizeof(wchar_t))+ sizeof(wchar_t);
		std::vector<char> buf(dataSize);
		
		PA_ConvertCharsetToCharset((char *)t.getUTF16StringPtr(),
															 t.getUTF16Length() * sizeof(PA_Unichar),
															 eVTC_UTF_16,
															 (char *)&buf[0],
															 dataSize,
															 eVTC_UTF_32);
		
		u32 = std::wstring((wchar_t *)&buf[0]);
		
	}else
	{
		u32 = L"";
	}
	
}

void json_set_s(JSONNODE *n, json_char *key, const char *value)
{
	if(n)
	{
		if(value)
		{
			std::wstring w32;
			json_wconv(value, w32);
			
			JSONNODE *e = json_get(n, key);
			if(e)
			{
				json_set_a(e, w32.c_str());//over-write existing value
			}else
			{
				json_push_back(n, json_new_a(key, w32.c_str()));
			}
			
		}else
		{
			JSONNODE *e = json_get(n, key);
			if(e)
			{
				json_nullify(e);//over-write existing value
			}else
			{
				JSONNODE *node = json_new_a(key, L"");
				json_nullify(node);
				json_push_back(n, node);
			}
		}
	}
}

void json_set_i(JSONNODE *n, json_char *key, int value)
{
	if(n)
	{
		JSONNODE *e = json_get(n, key);
		if(e)
		{
			json_set_b(e, value);//over-write existing value
		}else
		{
			json_push_back(n, json_new_i(key, value));
		}
	}
}

static const char json_x_table[65] = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";

void json_set_x(JSONNODE *n, json_char *key, void *payload, size_t binlen)
{
	std::vector<uint8_t>buf(binlen);
	if(payload)
	{
		PA_MoveBlock(payload, (char *)&buf[0], binlen);
		
		::std::size_t olen = (((binlen + 2) / 3) * 4);
		olen += olen / 72; /* line feeds */
		// Use = signs so the end is properly padded.
		std::string retval(olen, '=');
		::std::size_t outpos = 0;
		::std::size_t line_len = 0;
		int bits_collected = 0;
		unsigned int accumulator = 0;
		const std::vector<uint8_t>::const_iterator binend = buf.end();
		for (std::vector<uint8_t>::const_iterator i = buf.begin(); i != binend; ++i)
		{
			accumulator = (accumulator << 8) | (*i & 0xffu);
			bits_collected += 8;
			while (bits_collected >= 6)
			{
				bits_collected -= 6;
				retval[outpos++] = json_x_table[(accumulator >> bits_collected) & 0x3fu];
				line_len++;
				if (line_len >= 72) {
					retval[outpos++] = '\n';
					line_len = 0;
					//breathe every 8KO
					if((outpos % 0x2000)==0) {
						PA_YieldAbsolute();
					}
				}
			}
		}
		if (bits_collected > 0) { // Any trailing bits that are missing.
			//	assert(bits_collected < 6);
			accumulator <<= 6 - bits_collected;
			retval[outpos++] = json_x_table[accumulator & 0x3fu];
		}
		json_set_s(n, key, retval.c_str());
	}
}

#pragma mark -

static void rd_error_cb (rd_kafka_t *rk, int err, const char *reason, void *_opaque)
{
	rd_opaque *opaque = (rd_opaque *)_opaque;
	switch (err)
	{
		case RD_KAFKA_RESP_ERR__TRANSPORT:
		case RD_KAFKA_RESP_ERR__ALL_BROKERS_DOWN:
			opaque->run = 0;
			break;
			
  default:
			break;
	}
	opaque->err = (rd_kafka_resp_err_t)err;
}

static void rd_consume_cb (rd_kafka_message_t *rkmessage, rd_opaque *opaque, BOOL isBalanced)
{
	if (rkmessage->err)
	{
		if (rkmessage->err == RD_KAFKA_RESP_ERR__PARTITION_EOF)
		{
			if(isBalanced)
			{
				/*
			 fprintf(stderr,
							 "%% Consumer reached end of %s [%"PRId32"] "
							 "message queue at offset %"PRId64"\n",
							 rd_kafka_topic_name(rkmessage->rkt),
							 rkmessage->partition, rkmessage->offset);
				*/
				opaque->wait_eof = opaque->wait_eof - 1;
				if (opaque->exit_eof && opaque->wait_eof == 0)
					opaque->run = 0;
			}else
			{
				if (opaque->exit_eof)
					opaque->run = 0;
			}
	
			return;
		}

		if (rkmessage->err == RD_KAFKA_RESP_ERR__UNKNOWN_PARTITION ||
				rkmessage->err == RD_KAFKA_RESP_ERR__UNKNOWN_TOPIC ||
				rkmessage->err == RD_KAFKA_RESP_ERR__UNKNOWN_GROUP)
			opaque->run = 0;
		
		return;
	}
	
	JSONNODE *json = (JSONNODE *)opaque->json;
	JSONNODE *json_item = json_new(JSON_NODE);
	json_set_i(json_item, L"partition", rkmessage->partition);
	json_set_i(json_item, L"offset", rkmessage->offset);
	json_set_i(json_item, L"len", rkmessage->len);
	json_set_s(json_item, L"topic", rd_kafka_topic_name(rkmessage->rkt));
	
	if (rkmessage->key_len)
	{
		json_set_s(json_item, L"key", (const char *)rkmessage->key);
		json_set_i(json_item, L"key_len", rkmessage->key_len);
	}
	
	rd_kafka_timestamp_type_t tstype;
	int64_t timestamp = rd_kafka_message_timestamp(rkmessage, &tstype);
	
	char buffer[20];
#if VERSIONMAC
	sprintf(buffer, "%"PRIu64"", timestamp);
#else
	sprintf(buffer, "%llu", timestamp);
#endif
	switch (tstype)
	{
		case RD_KAFKA_TIMESTAMP_NOT_AVAILABLE:
			
			break;
			
		case RD_KAFKA_TIMESTAMP_CREATE_TIME:
			json_set_s(json_item, L"create_time", buffer);
			break;
			
		case RD_KAFKA_TIMESTAMP_LOG_APPEND_TIME:
			json_set_s(json_item, L"append_time", buffer);
			break;
	}
	
	CUTF8String str = CUTF8String((const uint8_t *)rkmessage->payload, rkmessage->len);
	json_set_s(json_item, L"value", (const char *)str.c_str());
	json_set_x(json_item, L"data", rkmessage->payload, rkmessage->len);
	
	json_push_back(json, json_item);
}

static void rd_produce_cb (rd_kafka_t *rk,
													 const rd_kafka_message_t *rkmessage,
													 void *opaque)
{
	JSONNODE *json = (JSONNODE *)rkmessage->_private;
	
	if (rkmessage->err)
	{
		JSONNODE *json_item = json_new(JSON_NODE);
		json_set_i(json_item, L"error", rkmessage->err);
		json_push_back(json, json_item);
	}
	else
	{
		JSONNODE *json_item = json_new(JSON_NODE);
		json_set_i(json_item, L"len", rkmessage->len);
		json_set_i(json_item, L"partition", rkmessage->partition);
		json_set_i(json_item, L"offset", rkmessage->offset);
		json_set_s(json_item, L"topic", rd_kafka_topic_name(rkmessage->rkt));
		if (rkmessage->key_len)
		{
			json_set_s(json_item, L"key", (const char *)rkmessage->key);
			json_set_i(json_item, L"key_len", rkmessage->key_len);
		}
		rd_kafka_timestamp_type_t tstype;
		int64_t timestamp = rd_kafka_message_timestamp(rkmessage, &tstype);
		
		char buffer[20];
#if VERSIONMAC
		sprintf(buffer, "%"PRIu64"", timestamp);
#else
		sprintf(buffer, "%llu", timestamp);
		
#endif
		switch (tstype)
		{
			case RD_KAFKA_TIMESTAMP_NOT_AVAILABLE:
				
				break;
				
			case RD_KAFKA_TIMESTAMP_CREATE_TIME:
				json_set_s(json_item, L"create_time", buffer);
				break;
				
			case RD_KAFKA_TIMESTAMP_LOG_APPEND_TIME:
				json_set_s(json_item, L"append_time", buffer);
				break;
		}
		
		CUTF8String str = CUTF8String((const uint8_t *)rkmessage->payload, rkmessage->len);
		json_set_s(json_item, L"value", (const char *)str.c_str());
		json_set_x(json_item, L"data", rkmessage->payload, rkmessage->len);
		
		json_push_back(json, json_item);
	}
	
}

#pragma mark -

void PluginMain(PA_long32 selector, PA_PluginParameters params)
{
	try
	{
		PA_long32 pProcNum = selector;
		sLONG_PTR *pResult = (sLONG_PTR *)params->fResult;
		PackagePtr pParams = (PackagePtr)params->fParameters;

		CommandDispatcher(pProcNum, pResult, pParams); 
	}
	catch(...)
	{

	}
}

void CommandDispatcher (PA_long32 pProcNum, sLONG_PTR *pResult, PackagePtr pParams)
{
	switch(pProcNum)
	{
		case kInitPlugin :
		case kServerInitPlugin :
			OnStartup();
			break;
			
		case kCloseProcess :
			OnCloseProcess();
			break;
			
			// --- RDKAFKA

		case 1 :
			KAFKA_Consume(pResult, pParams);
			break;
			
		case 2 :
			KAFKA_Produce(pResult, pParams);
			break;
			
		case 3 :
			KAFKA_Get_version(pResult, pParams);
			break;
			
		case 4 :
			KAFKA_Get_topics(pResult, pParams);
			break;
			
		case 5 :
			KAFKA_Get_groups(pResult, pParams);
			break;
			
	}
}

// ------------------------------------ RDKAFKA -----------------------------------

#pragma mark -

static void rebalance_cb (rd_kafka_t *rk,
													rd_kafka_resp_err_t err,
													rd_kafka_topic_partition_list_t *partitions,
													void *_opaque)
{
	rd_opaque *opaque = (rd_opaque *)_opaque;
	switch (err)
	{
		case RD_KAFKA_RESP_ERR__ASSIGN_PARTITIONS:
			rd_kafka_assign(rk, partitions);
			opaque->wait_eof += partitions->cnt;
			break;
			
		case RD_KAFKA_RESP_ERR__REVOKE_PARTITIONS:
			rd_kafka_assign(rk, NULL);
			opaque->wait_eof = 0;
			break;
			
		default:
			rd_kafka_assign(rk, NULL);
			break;
	}
}

void __(ARRAY_TEXT& Param1_brokers, const char *topic,
				int32_t partition, int64_t start,
				rd_opaque *opaque, int64_t *count, int64_t *total)
{
	C_LONGINT returnValue;	
	rd_kafka_conf_t *conf = rd_kafka_conf_new();
	if(conf)
	{
		rd_kafka_conf_set_opaque(conf, (void *)opaque);
		rd_kafka_conf_set_error_cb(conf, rd_error_cb);
		
		rd_kafka_t *rk = rd_new(RD_KAFKA_CONSUMER, conf);
		if (rk)
		{
			if(rd_kafka_set_rk_brokers(Param1_brokers, rk, returnValue))
			{
				rd_kafka_topic_conf_t *topic_conf = rd_kafka_topic_conf_new();
				if(topic_conf)
				{
					rd_kafka_topic_t *rkt = rd_topic_new(rk, topic, topic_conf, returnValue);
					if(rkt)
					{
						if (rd_consume_start(rkt, partition, start, returnValue) != RD_KAFKA_RESP_ERR_UNKNOWN)
						{
							int run = opaque->run;
							opaque->run = 1;
							while (opaque->run)
							{
								PA_YieldAbsolute();
								rd_kafka_poll(rk, 0);/* call cb */
								rd_kafka_message_t *rkmessage = rd_kafka_consume(rkt, partition, 1000);
								
								if (!rkmessage) /* timeout */{
									continue;
								}
							
								rd_consume_cb(rkmessage, opaque, FALSE);
								rd_kafka_message_destroy(rkmessage);
								
								if (!rkmessage->err)
								{
									*total = *total + 1;
								}

								if(*total == *count)
									break;
								
							}/* opaque.run */
							opaque->run = run;
						}
						/* Stop consuming */
						rd_kafka_consume_stop(rkt, partition);
						
						while (rd_kafka_outq_len(rk) > 0)
							rd_kafka_poll(rk, 10);
						
						rd_kafka_topic_destroy(rkt);
					}
				}
			}
			rd_kafka_destroy(rk);
		}
	}
}

#pragma mark -

void KAFKA_Consume(sLONG_PTR *pResult, PackagePtr pParams)
{
	ARRAY_TEXT Param1_brokers;
	C_TEXT Param2_topic;
	C_TEXT Param3_options;
	C_LONGINT Param4_partition;
	C_TEXT Param5_group;
	C_LONGINT Param6_offset;
	C_LONGINT Param7_count;
	C_LONGINT returnValue;
	
	Param1_brokers.fromParamAtIndex(pParams, 1);
	Param2_topic.fromParamAtIndex(pParams, 2);
	Param4_partition.fromParamAtIndex(pParams, 4);
	Param5_group.fromParamAtIndex(pParams, 5);
	Param6_offset.fromParamAtIndex(pParams, 6);
	Param7_count.fromParamAtIndex(pParams, 7);
	
	JSONNODE *json = json_new(JSON_ARRAY);
	
	CUTF8String topic;
	Param2_topic.copyUTF8String(&topic);

	CUTF8String group;
	Param5_group.copyUTF8String(&group);
	
	int64_t offset = Param6_offset.getIntValue();
	int64_t count = Param7_count.getIntValue();
	int64_t total = 0;

	count = (count < 0) ? 0 : count;
	
	rd_kafka_resp_err_t err = RD_KAFKA_RESP_ERR_NO_ERROR;
	rd_kafka_conf_res_t res = RD_KAFKA_CONF_OK;
	
	rd_opaque opaque;
	opaque.exit_eof = 1;
	opaque.wait_eof = 0;
	opaque.run = 1;
	opaque.json = json;
	opaque.err = RD_KAFKA_RESP_ERR_NO_ERROR;
	
	rd_kafka_conf_t *conf = rd_kafka_conf_new();
	if(conf)
	{
		rd_kafka_conf_set_opaque(conf, (void *)&opaque);
		rd_kafka_conf_set_error_cb(conf, rd_error_cb);
		
		int32_t partition = Param4_partition.getIntValue();
		
		/* balanced consumer groups */
		if(partition == RD_KAFKA_PARTITION_UA)
		{
			rd_kafka_conf_set_rebalance_cb(conf, rebalance_cb);
			if(group.length())
			{
				res = rd_kafka_set_conf_group(conf, (const char *)group.c_str(), returnValue);
			}
		}
		rd_kafka_t *rk = rd_new(RD_KAFKA_CONSUMER, conf);
		if (rk)
		{
			if(rd_kafka_set_rk_brokers(Param1_brokers, rk, returnValue))
			{
				/* static assignment */
				if(partition != RD_KAFKA_PARTITION_UA)
				{
					int64_t lo = 0, hi = 0;
					int timeout_ms = 5000;
					if(offset)
					{
						if(RD_KAFKA_RESP_ERR_NO_ERROR == rd_kafka_query_watermark_offsets(
																																							rk,
																																							(const char *)topic.c_str(),
																																							partition,
																																							&lo, &hi,
																																							timeout_ms))
						{
							if(offset < 0)
							{
								offset = hi + offset;
							}
								offset = ((offset < hi) && (offset > lo)) ? offset : lo;
						}
						
					}
					if(topic.length())
					{
						rd_kafka_topic_conf_t *topic_conf = rd_kafka_topic_conf_new();
						if(topic_conf)
						{
							rd_kafka_topic_t *rkt = rd_topic_new(rk, (const char *)topic.c_str(), topic_conf, returnValue);
							if(rkt)
							{
								if (rd_consume_start(rkt, partition, offset, returnValue) != RD_KAFKA_RESP_ERR_UNKNOWN)
								{
									while (opaque.run)
									{
										PA_YieldAbsolute();
										rd_kafka_poll(rk, 0);/* call cb */
										rd_kafka_message_t *rkmessage = rd_kafka_consume(rkt, partition, 1000);
										
										if (!rkmessage) /* timeout */{
											continue;
										}
										rd_consume_cb(rkmessage, &opaque, FALSE);
										rd_kafka_message_destroy(rkmessage);
										
										if (!rkmessage->err)
										{
											total = total + 1;
										}
										
										if(total == count)
											break;
										
										/*
										if(count && (count < (2 + rkmessage->offset - offset)))
											break;
										*/
										
									}/* opaque.run */
									
									/* Stop consuming */
									rd_kafka_consume_stop(rkt, partition);
									
									while (rd_kafka_outq_len(rk) > 0)
										rd_kafka_poll(rk, 10);
									
									rd_kafka_topic_destroy(rkt);
								}
							}
						}
					}
				}else
				{
					partition = 0;
					/* RD_KAFKA_PARTITION_UA */
					if(topic.length())
					{
						rd_kafka_topic_conf_t *topic_conf = rd_kafka_topic_conf_new();
						if(topic_conf)
						{
							offset = (offset < 0) ? 0 : offset;/* no relative index in this mode */
							rd_kafka_conf_set_default_topic_conf(conf, topic_conf);
							rd_kafka_topic_partition_list_t *topics;
							topics = rd_kafka_topic_partition_list_new(9);
							rd_kafka_topic_partition_list_add(topics, (const char *)topic.c_str(), partition);
							err = rd_kafka_subscribe(rk, topics);
							rd_kafka_poll_set_consumer(rk);
							
							while (opaque.run)
							{
								PA_YieldAbsolute();
								rd_kafka_message_t *rkmessage = rd_kafka_consumer_poll(rk, 1000);
								
								if (!rkmessage) /* timeout */{
									continue;
								}
								
								rd_consume_cb(rkmessage, &opaque, TRUE);
								
								if (rkmessage->err)
								{
									if (rkmessage->err == RD_KAFKA_RESP_ERR__PARTITION_EOF)
									{
										if(rkmessage->offset)
										{
											if(rkmessage->offset > offset)
											{
												__(Param1_brokers,
													 rd_kafka_topic_name(rkmessage->rkt),
													 rkmessage->partition,
													 offset, &opaque, &count, &total);
												offset = 0;
											}else{
												offset = offset - rkmessage->offset;
											}
										}
									}
								}
								rd_kafka_message_destroy(rkmessage);
							}
						}

					}
				}
			}
			rd_kafka_destroy(rk);
		}
	}

	/* return values */

	json_stringify(json, Param3_options, FALSE);
	json_delete(json);
	Param3_options.toParamAtIndex(pParams, 3);
	if(opaque.err)
		returnValue.setIntValue(opaque.err);
	returnValue.setReturn(pResult);
}

void KAFKA_Produce(sLONG_PTR *pResult, PackagePtr pParams)
{
	ARRAY_TEXT Param1_brokers;
	C_TEXT Param2_topic;
	C_BLOB Param3_payload;
	C_TEXT Param4_key;
	C_TEXT Param5_options;
	C_LONGINT Param6_partition;
	C_LONGINT returnValue;
	
	Param1_brokers.fromParamAtIndex(pParams, 1);
	Param2_topic.fromParamAtIndex(pParams, 2);
	Param3_payload.fromParamAtIndex(pParams, 3);
	Param4_key.fromParamAtIndex(pParams, 4);
	Param6_partition.fromParamAtIndex(pParams, 6);
	
	JSONNODE *json = json_new(JSON_ARRAY);
	
	rd_opaque opaque;
	opaque.exit_eof = 1;
	opaque.wait_eof = 0;
	opaque.run = 1;
	opaque.json = json;
	opaque.err = RD_KAFKA_RESP_ERR_NO_ERROR;
	
	CUTF8String topic;
	Param2_topic.copyUTF8String(&topic);

	CUTF8String key;
	Param4_key.copyUTF8String(&key);
	
	rd_kafka_conf_t *conf = rd_kafka_conf_new();
	if(conf)
	{
		rd_kafka_conf_set_opaque(conf, (void *)&opaque);
		rd_kafka_conf_set_error_cb(conf, rd_error_cb);
		
		rd_kafka_conf_res_t res = rd_kafka_set_conf_brokers(Param1_brokers, conf, returnValue);
		if (res == RD_KAFKA_CONF_OK)
		{
			rd_kafka_conf_set_dr_msg_cb(conf, rd_produce_cb);
			
			rd_kafka_t *rk = rd_new(RD_KAFKA_PRODUCER, conf);
			if (rk)
			{
				if(topic.length())
				{
					rd_kafka_topic_t *rkt = rd_topic_new(rk, (const char *)topic.c_str(), NULL, returnValue);
					if (rkt)
					{
						char *buf = (char *)Param3_payload.getBytesPtr();
						size_t len = Param3_payload.getBytesLength();
						int32_t partition = Param6_partition.getIntValue();
						
						while (opaque.run)
						{
						retry:
							PA_YieldAbsolute();
							if (rd_kafka_produce(
																	 rkt,
																	 partition,
																	 RD_KAFKA_MSG_F_COPY,
																	 buf, len,
																	 key.length() ? key.c_str() : NULL, key.length(),
																	 json) == RD_KAFKA_RESP_ERR_UNKNOWN)
							{
								if (rd_kafka_last_error() == RD_KAFKA_RESP_ERR__QUEUE_FULL)
								{
									/* busy */
									rd_kafka_poll(rk, 1000/*block for max 1000ms*/);
									goto retry;
								}/* RD_KAFKA_RESP_ERR__QUEUE_FULL */
							}else
							{
								opaque.run = 0;
							}
							rd_kafka_poll(rk, 10);
						}/* while */
						rd_kafka_flush(rk, 5000 /* wait for max 5 seconds */);
						rd_kafka_topic_destroy(rkt);
					}
				}
				rd_kafka_destroy(rk);
			}
		}
	}
	
	/* return values */
	
	json_stringify(json, Param5_options, FALSE);
	json_delete(json);
	Param5_options.toParamAtIndex(pParams, 5);
	if(opaque.err)
		returnValue.setIntValue(opaque.err);
	returnValue.setReturn(pResult);
}

#pragma mark -

void KAFKA_Get_version(sLONG_PTR *pResult, PackagePtr pParams)
{
	C_TEXT returnValue;
	CUTF8String version = (const uint8_t*)rd_kafka_version_str();
	returnValue.setUTF8String(&version);
	returnValue.setReturn(pResult);
}

#pragma mark -

void check_connection(rd_kafka_t *rk)
{
	rd_kafka_resp_err_t err = RD_KAFKA_RESP_ERR_NO_ERROR;
	rd_kafka_topic_conf_t *topic_conf = rd_kafka_topic_conf_new();
	if(topic_conf)
	{
		int32_t partition = 0;
		int64_t offset = 0;
		C_LONGINT returnValue;
		rd_kafka_topic_t *rkt = rd_topic_new(rk, (const char *)".", topic_conf, returnValue);
		if(rkt)
		{
			if (rd_consume_start(rkt, partition, offset, returnValue) != RD_KAFKA_RESP_ERR_UNKNOWN)
			{
				rd_kafka_poll(rk, 5000);
				rd_kafka_consume_stop(rkt, partition);
			}
			rd_kafka_topic_destroy(rkt);
		}
	}
}

#pragma mark -

void json_topic_list(JSONNODE *json, const struct rd_kafka_metadata *metadata, CUTF8String& topic)
{
	JSONNODE *json_item = json_new(JSON_NODE);
	json_set_s(json_item, L"topic", topic.length() ? (const char *)topic.c_str() : (const char *)"*");
	json_set_i(json_item, L"orig_broker_id", metadata->orig_broker_id);
	json_set_s(json_item, L"orig_broker_name", metadata->orig_broker_name);
	
	/* brokers */
	JSONNODE *json_item_brokers = json_new(JSON_ARRAY);
	for (int i = 0 ; i < metadata->broker_cnt ; ++i)
	{
		JSONNODE *json_item_broker = json_new(JSON_NODE);
		const struct rd_kafka_metadata_broker *b = &metadata->brokers[i];
		json_set_i(json_item_broker, L"port", b->port);
		json_set_i(json_item_broker, L"id", b->id);
		json_set_s(json_item_broker, L"host", b->host);
		json_push_back(json_item_brokers, json_item_broker);
	}
	json_push_back(json_item, json_item_brokers);
	json_set_name(json_item_brokers, L"brokers");
	
	/* topics */
	JSONNODE *json_item_topics = json_new(JSON_ARRAY);
	for (int i = 0 ; i < metadata->topic_cnt ; ++i)
	{
		if((i % 0x2000)==0)
		{
			PA_YieldAbsolute();
		}
		JSONNODE *json_item_topic = json_new(JSON_NODE);
		const struct rd_kafka_metadata_topic *t = &metadata->topics[i];
		json_set_s(json_item_topic, L"topic", t->topic);
		
		JSONNODE *json_item_partitions = json_new(JSON_ARRAY);
		for (int j = 0 ; j < t->partition_cnt ; ++j)
		{
			JSONNODE *json_item_partition = json_new(JSON_NODE);
			const struct rd_kafka_metadata_partition *p = &t->partitions[j];
			json_set_i(json_item_partition, L"id", p->id);
			json_set_i(json_item_partition, L"leader", p->leader);
			json_push_back(json_item_partitions, json_item_partition);
		}
		json_push_back(json_item_topic, json_item_partitions);
		json_set_name(json_item_partitions, L"partitions");
		json_push_back(json_item_topics, json_item_topic);
	}
	json_push_back(json_item, json_item_topics);
	json_set_name(json_item_topics, L"topics");

	json_push_back(json, json_item);
}

void KAFKA_Get_topics(sLONG_PTR *pResult, PackagePtr pParams)
{
	ARRAY_TEXT Param1_brokers;
	C_TEXT Param2_topic;
	C_TEXT Param3_options;
	C_LONGINT returnValue;
	
	Param1_brokers.fromParamAtIndex(pParams, 1);
	Param2_topic.fromParamAtIndex(pParams, 2);
	
	JSONNODE *json = json_new(JSON_ARRAY);

	rd_opaque opaque;
	opaque.exit_eof = 1;
	opaque.wait_eof = 0;
	opaque.run = 1;
	opaque.json = json;
	opaque.err = RD_KAFKA_RESP_ERR_NO_ERROR;
	
	CUTF8String topic;
	Param2_topic.copyUTF8String(&topic);
	
	rd_kafka_conf_t *conf = rd_kafka_conf_new();
	if(conf)
	{
		rd_kafka_conf_set_opaque(conf, (void *)&opaque);
		rd_kafka_conf_set_error_cb(conf, rd_error_cb);
		
		if (rd_kafka_set_conf_brokers(Param1_brokers, conf, returnValue) == RD_KAFKA_CONF_OK)
		{
			rd_kafka_t *rk = rd_new(RD_KAFKA_CONSUMER, conf);
			if(rk)
			{
				check_connection(rk);
				if(opaque.err == RD_KAFKA_RESP_ERR_NO_ERROR)
				{
					rd_kafka_topic_t *rkt = NULL;
					if(topic.length())
					{
						rkt = rd_kafka_topic_new(rk, (const char *)topic.c_str(), NULL);
					}
					const struct rd_kafka_metadata *metadata;
					
					if(rd_metadata(rk, rkt, &metadata, returnValue) == RD_KAFKA_RESP_ERR_NO_ERROR)
					{
						json_topic_list(json, metadata, topic);
						rd_kafka_metadata_destroy(metadata);
					}
					if (rkt)
					{
						rd_kafka_topic_destroy(rkt);
					}
				}
				rd_kafka_destroy(rk);
			}
		}
	}

	/* return values */
	
	json_stringify(json, Param3_options, FALSE);
	json_delete(json);
	Param3_options.toParamAtIndex(pParams, 3);
	if(opaque.err)
		returnValue.setIntValue(opaque.err);
	returnValue.setReturn(pResult);
}

#pragma mark

void json_group_list(JSONNODE *json, const struct rd_kafka_group_list *grplist)
{
	/* groups */
	JSONNODE *json_item_groups = json_new(JSON_ARRAY);
	for (int i = 0 ; i < grplist->group_cnt ; ++i)
	{
		const struct rd_kafka_group_info *gi = &grplist->groups[i];
		JSONNODE *json_item_group = json_new(JSON_NODE);
		json_set_s(json_item_group, L"group", gi->group);
		json_set_s(json_item_group, L"state", gi->state);
		json_set_i(json_item_group, L"broker_id", gi->broker.id);
		json_set_i(json_item_group, L"broker_port", gi->broker.port);
		json_set_s(json_item_group, L"broker_host", gi->broker.host);
		json_set_s(json_item_group, L"protocol_type", gi->protocol_type);
		json_set_s(json_item_group, L"protocol", gi->protocol);
		/* members */
		JSONNODE *json_item_members = json_new(JSON_ARRAY);
		for (int j = 0 ; j < gi->member_cnt ; ++j)
		{
			const struct rd_kafka_group_member_info *mi = &gi->members[j];
			JSONNODE *json_item_member = json_new(JSON_NODE);
			json_set_s(json_item_member, L"member_id", mi->member_id);
			json_set_s(json_item_member, L"client_id", mi->client_id);
			json_set_s(json_item_member, L"client_host", mi->client_host);
			json_set_i(json_item_member, L"member_assignment_size", mi->member_assignment_size);
			json_set_i(json_item_member, L"member_metadata_size", mi->member_metadata_size);
			json_push_back(json_item_members, json_item_member);
		}
		json_push_back(json_item_group, json_item_members);
		json_set_name(json_item_members, L"members");
		json_push_back(json, json_item_group);
	}
	
}

void KAFKA_Get_groups(sLONG_PTR *pResult, PackagePtr pParams)
{
	ARRAY_TEXT Param1_brokers;
	C_TEXT Param2_groups;
	C_LONGINT returnValue;
	
	Param1_brokers.fromParamAtIndex(pParams, 1);
	
	JSONNODE *json = json_new(JSON_ARRAY);
	
	rd_opaque opaque;
	opaque.exit_eof = 1;
	opaque.wait_eof = 0;
	opaque.run = 1;
	opaque.json = json;
	opaque.err = RD_KAFKA_RESP_ERR_NO_ERROR;
	
	rd_kafka_conf_t *conf = rd_kafka_conf_new();
	if(conf)
	{
		rd_kafka_conf_set_opaque(conf, (void *)&opaque);
		rd_kafka_conf_set_error_cb(conf, rd_error_cb);
		
		if (rd_kafka_set_conf_brokers(Param1_brokers, conf, returnValue) == RD_KAFKA_CONF_OK)
		{
			rd_kafka_t *rk = rd_new(RD_KAFKA_CONSUMER, conf);
			if(rk)
			{
				check_connection(rk);
				if(opaque.err == RD_KAFKA_RESP_ERR_NO_ERROR)
				{
					int timeout_ms = 5000;
					const struct rd_kafka_group_list *grplist;
					if(rd_kafka_list_groups (rk,
																	 NULL,
																	 &grplist,
																	 timeout_ms) == RD_KAFKA_RESP_ERR_NO_ERROR)
					{
						json_group_list(json, grplist);
						rd_kafka_group_list_destroy(grplist);
					}else/* rd_kafka_list_groups */{
						returnValue.setIntValue(rd_kafka_last_error());
					}
				}
				rd_kafka_destroy(rk);
			}
		}
	}
	
	/* return values */
	
	json_stringify(json, Param2_groups, FALSE);
	json_delete(json);
	Param2_groups.toParamAtIndex(pParams, 2);
	if(opaque.err)
		returnValue.setIntValue(opaque.err);
	returnValue.setReturn(pResult);
}
